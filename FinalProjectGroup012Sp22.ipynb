{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project : An Insight on the Correlation of Social Media Impressions and Box Office Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [  ] YES - make available\n",
    "* [ X ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we explore if several tweet factors indicate a likelihood of a higher box offices for the top 100 movies of 2021. We explore our data by graphing the box offices of our selection of movies, finding the frequency distribution of words in select movies and measuring sentiment for each tweet in our dataset. We move on to create linear regression models with scatterplots to measure correlations between tweet count and boxoffices as well as tweet sentiment and box offices. We find that our data supports our hypthothesis and that their is a corelation between the aforementioned variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "  - Fajar Dirham\n",
    "  - Robbie Kovar\n",
    "  - Erik Cisneros\n",
    "  - Julie Ngan\n",
    "  - Mohamed Abdilahi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the amount of positive and negative tweets affect how well American movies do in the box office?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "\n",
    "## Background & Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to quantify how social media affects the real world is not a new idea. The specific question we are trying to ask, relating social media impressions and box office success for movies, has been explored by other parties in the past. A thesis paper from the University of Miami school of communication found positive correlation coefficients between engagements in Instagram, Facebook, and Twitter and box office numbers[^dejesus]. In the paper, engagements were calculated by accounting for the followers of posts. The author took movies from Rotten Tomatoes, used Box Office Mojo for revenue data, and used Rival IQ (a social media platform analytics service). These positive correlation coefficients suggest that there \"exists a moderate or strong positive correlation between engagement rates and box office for limited release films\".\n",
    "\n",
    "Another similar study by Neuralink and Facebook hoping to uncover the impact social media has on a movie’s success, particularly box office sales, found that Facebook ads contributed a significant portion to a movie’s marketing (20%) despite only accounting for a small percentage of its expenditure (4%).[^meta] In other words, the budget spent on Facebook ads ended up having a larger impact than its cost would entail. In the study they acknowledge how social media has become a competitive platform for media consumption, likening it to how television was revolutionary in marketing back in its heyday. Similarly, our group acknowledges how social media has become an influential and impactful communication platform, replacing traditional methods of self-expression such as word of mouth with the publishing of public posts. As such we hope to uncover if the brief mention of movie titles in people’s posts, has the potential to drive up sales for movies.\n",
    "\n",
    "References (include links):\n",
    "- 1) De Jesus, Kimberly. “Social Media Engagement and Film Box Office.” University of Miami School of Communication, 2020. [^meta]: “New: Study Unveils Secrets to Box Office Marketing.” Meta for Business, https://www.facebook.com/business/m/verticals/entertainment-media/social-media-impact-on-movie-attendance.\n",
    "- 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that the more social media impressions a movie has before coming out results in it doing better in the box office in its opening weekend, regardless of if the impressions are positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1\n",
    "\n",
    "    Dataset Name: Movie Report\n",
    "    Link to the dataset: https://www.the-numbers.com/movies/report/All/All/All/All/All/All/United-States/All/All/None/None/2021/2021/None/None/None/None/None/None?show-release-date=On&show-domestic-box-office=On&show-international-box-office=On&show-worldwide-box-office=On&view-order-by=domestic-box-office&view-order-direction=desc\n",
    "    Number of observations: 100\n",
    "\n",
    "This dataset is the list of the top 100 American movies domestically, internationally, and worldwide. We will use this dataset to help us answer our research question on whether the amount of tweets is correlated to how well it does commercially.\n",
    "DataSet 2\n",
    "\n",
    "    Dataset Name: Tweets\n",
    "    Link to the dataset: N/A, webscraped\n",
    "    Number of observations: 801928\n",
    "\n",
    "This dataset is scraped from Twitter, using a 3rd party scraping tool, snscrape. Using the titles found in the Movie Report dataset, we will fetch the number of tweets that reference these titles, and list them with a tweet for each row. This dataset has a column marked 'movie_id' which corresponds to which movie the tweet is from and its index in the Movie Report datset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read MovieReport.csv into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Released</th>\n",
       "      <th>Title</th>\n",
       "      <th>Domestic\\r\\nBox Office</th>\n",
       "      <th>International\\r\\nBox Office</th>\n",
       "      <th>Worldwide\\r\\nBox Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 17, 2021</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>$804,617,772</td>\n",
       "      <td>$1,083,808,579</td>\n",
       "      <td>$1,888,426,351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sep 3, 2021</td>\n",
       "      <td>Shang-Chi and the Legend of the Ten R…</td>\n",
       "      <td>$224,543,292</td>\n",
       "      <td>$207,700,000</td>\n",
       "      <td>$432,243,292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oct 1, 2021</td>\n",
       "      <td>Venom: Let There be Carnage</td>\n",
       "      <td>$213,550,366</td>\n",
       "      <td>$288,050,013</td>\n",
       "      <td>$501,600,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jul 9, 2021</td>\n",
       "      <td>Black Widow</td>\n",
       "      <td>$183,651,655</td>\n",
       "      <td>$196,100,000</td>\n",
       "      <td>$379,751,655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun 25, 2021</td>\n",
       "      <td>F9: The Fast Saga</td>\n",
       "      <td>$173,005,945</td>\n",
       "      <td>$548,072,000</td>\n",
       "      <td>$721,077,945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Released                                   Title  \\\n",
       "1  Dec 17, 2021                 Spider-Man: No Way Home   \n",
       "2   Sep 3, 2021  Shang-Chi and the Legend of the Ten R…   \n",
       "3   Oct 1, 2021             Venom: Let There be Carnage   \n",
       "4   Jul 9, 2021                             Black Widow   \n",
       "5  Jun 25, 2021                       F9: The Fast Saga   \n",
       "\n",
       "  Domestic\\r\\nBox Office International\\r\\nBox Office Worldwide\\r\\nBox Office  \n",
       "1           $804,617,772              $1,083,808,579          $1,888,426,351  \n",
       "2           $224,543,292                $207,700,000            $432,243,292  \n",
       "3           $213,550,366                $288,050,013            $501,600,379  \n",
       "4           $183,651,655                $196,100,000            $379,751,655  \n",
       "5           $173,005,945                $548,072,000            $721,077,945  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('MovieReport.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 webscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script snscrape is installed in '/home/rkovar/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# installation of webscraper\n",
    "!pip install -q snscrape==0.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported libraries\n",
    "import os\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'Timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1918/2821238975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdate_released\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Released'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mdate_of_interest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_released\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdays_prerelease\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mposts_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_N_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_of_interest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_released\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposts_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'Timedelta'"
     ]
    }
   ],
   "source": [
    "# Parameters:\n",
    "days_prerelease = 14      # days before release to start search\n",
    "N = 100                   # number of posts to fetch; used to fetch first N posts\n",
    "tweets_df = pd.DataFrame()\n",
    "\n",
    "# for each title get a list of tuples.\n",
    "\n",
    "for index, title in enumerate(data['Title']):\n",
    "  date_released = data['Released'].iloc[index]\n",
    "  date_of_interest = date_released - pd.Timedelta(days=days_prerelease)\n",
    "  posts_list = get_N_posts(date_of_interest, date_released, title, N)\n",
    "  tweets = pd.Series(data=posts_list)\n",
    "  tweets_df[title] = tweets\n",
    "\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Report Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Function for getting the total number of tweets for a movie title\n",
    "# from_date - datetime object to start search\n",
    "# to_date - datetime object to stop search\n",
    "# title - string title of movie\n",
    "# returns int number of tweets for the movie \n",
    "def num_tweets(from_date, to_date, title):\n",
    "    start = str(from_date).replace(' 00:00:00', '')\n",
    "    end = str(to_date).replace(' 00:00:00', '')\n",
    "\n",
    "    os.system(f\"snscrape --since {start} twitter-search '{title} until:{end}' > result-tweets.txt\")\n",
    "    if os.stat(\"result-tweets.txt\").st_size == 0:\n",
    "       counter = 0\n",
    "    else:\n",
    "       df = pd.read_csv('result-tweets.txt', names=['link'])\n",
    "       counter = df.size\n",
    "    os.remove('result-tweets.txt')\n",
    "    print('Number Of Tweets : '+ str(counter))\n",
    "    return counter\n",
    "\n",
    "# Function for getting the total number of tweets for a movie title\n",
    "# from_date - datetime object to start search\n",
    "# to_date - datetime object to stop search\n",
    "# title - string title of movie\n",
    "# N - int number of posts to fetch\n",
    "# returns list of first N tweets about the movie title \n",
    "def get_N_posts(from_date, to_date, title, N):\n",
    "  posts_list = []\n",
    "  start = str(from_date).replace(' 00:00:00', '')\n",
    "  end = str(to_date).replace(' 00:00:00', '')\n",
    "  os.system(\"snscrape --format '{content!r}'\"+ f\" --max-results {N} --since {start} twitter-search '{title} until:{end}' > tweets.txt\")\n",
    "  if os.stat(\"tweets.txt\").st_size == 0:\n",
    "    os.remove('tweets.txt')\n",
    "    return posts_list\n",
    "  else:\n",
    "    df = pd.read_csv('tweets.txt', names=['content'])\n",
    "    for row in df['content'].iteritems():\n",
    "      posts_list.append(row)\n",
    "    os.remove('tweets.txt')\n",
    "    return posts_list\n",
    "\n",
    "# Function for converting date strings into pandas datatime objects\n",
    "# start - string datetime to start search\n",
    "# end - string datetime to stop search\n",
    "# title - string title of movie\n",
    "# returns int number of tweets for the movie\n",
    "def standardize_date(str): \n",
    "  try:\n",
    "    str = str.strip()\n",
    "\n",
    "    str = str.replace('Jan ', \"01/\")\n",
    "    str = str.replace('Feb ', \"02/\")\n",
    "    str = str.replace('Mar ', \"03/\")\n",
    "    str = str.replace('Apr ', \"04/\")\n",
    "    str = str.replace('May ', \"05/\")\n",
    "    str = str.replace('Jun ', \"06/\")\n",
    "    str = str.replace('Jul ', \"07/\")\n",
    "    str = str.replace('Aug ', \"08/\")\n",
    "    str = str.replace('Sep ', \"09/\")\n",
    "    str = str.replace('Oct ', \"10/\")\n",
    "    str = str.replace('Nov ', \"11/\")\n",
    "    str = str.replace('Dec ', \"12/\")\n",
    "\n",
    "    str = str.replace(', ', \"/\")\n",
    "\n",
    "    str = str.replace('/1/', \"/01/\")\n",
    "    str = str.replace('/2/', \"/02/\")\n",
    "    str = str.replace('/3/', \"/03/\")\n",
    "    str = str.replace('/4/', \"/04/\")\n",
    "    str = str.replace('/5/', \"/05/\")\n",
    "    str = str.replace('/6/', \"/06/\")\n",
    "    str = str.replace('/7/', \"/07/\")\n",
    "    str = str.replace('/8/', \"/08/\")\n",
    "    str = str.replace('/9/', \"/09/\")\n",
    "\n",
    "    out = str\n",
    "  except:\n",
    "    out = \"n/a\" \n",
    "\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1918/4240653370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m data = data.rename(columns={\"Domestic\\r\\nBox Office\":\"Domestic Box Office\", \"International\\r\\nBox Office\":\"International Box Office\", \n\u001b[1;32m      3\u001b[0m            \"Worldwide\\r\\nBox Office\":\"Worldwide Box Office\"})\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Transformation of release date string to 'datetime' objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4905\u001b[0m         \"\"\"\n\u001b[0;32m-> 4906\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    " #simple renaming of columns so it can be easier to read\n",
    "data = data.rename(columns={\"Domestic\\r\\nBox Office\":\"Domestic Box Office\", \"International\\r\\nBox Office\":\"International Box Office\", \n",
    "            \"Worldwide\\r\\nBox Office\":\"Worldwide Box Office\"})\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Transformation of release date string to 'datetime' objects\n",
    "data['Released'] = data['Released'].apply(standardize_date)\n",
    "data['Released'] = data['Released'].apply(pd.to_datetime)\n",
    "\n",
    "# Sort Movies by release date\n",
    "data = data.sort_values(by='Released')\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "# Remove dollar signs and commas from the box office numbers and convert them to floats\n",
    "data['Domestic Box Office'] = data['Domestic Box Office'].str.replace('$','')\n",
    "data['Domestic Box Office'] = data['Domestic Box Office'].str.replace(',','').astype(float)\n",
    "data['International Box Office'] = data['International Box Office'].str.replace('$','')\n",
    "data['International Box Office'] = data['International Box Office'].str.replace(',','').astype(float)\n",
    "data['Worldwide Box Office'] = data['Worldwide Box Office'].str.replace('$','')\n",
    "data['Worldwide Box Office'] = data['Worldwide Box Office'].str.replace(',','').astype(float)\n",
    "\n",
    "# Remove null\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and clean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the tweets first\n",
    "def clean_text(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    to_return = ''\n",
    "    for word in text.split():\n",
    "        if not '@' in word and not 'https:' in word:\n",
    "            to_return += word + \" \"\n",
    "\n",
    "    to_return = to_return.replace(\"#\",\"\")\n",
    "    return to_return[0:len(to_return)-1]\n",
    "\n",
    "test_clean = clean_text(tweets_df.iloc[0]['tweet'])\n",
    "tweets_df[\"tweet_clean\"] = tweets_df['tweet'].apply(clean_text)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size\n",
    "For this dataset we have 100 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness\n",
    "Searching for any anomalous entries we found that 6 movies had an International Box Office of 0. We believe these movies didn't have an international box office because they only released domestically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic_only =  data[data['International Box Office'] == 0]\n",
    "domestic_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using box office as a measure of success for a movie, we will remove the aforementioned entries. Their lack of an international box office, makes it difficult to compare them with other movies at an international scope. Additionally it hinders their worldwide box office making them appear less successful than other movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['International Box Office'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a histogram for the release date of movies, we see that it is fairly uniformly distributed. There is a slight lack of movies during the first quarter the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='Released', bins=24)\n",
    "plt.title('Distribution of Movie Release Date Across 2021')\n",
    "plt.xticks(rotation=45)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting for Box Office success, we see all three distributions are highly skewed right. We also spot a few outliers who earned huge box offices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='Domestic Box Office', bins=24)\n",
    "plt.title('Distribution of Domestic Box Office')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='International Box Office', bins=24)\n",
    "plt.title('Distribution of International Box Office')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='Worldwide Box Office', bins=24)\n",
    "plt.title('Distribution of Worldwide Box Office')\n",
    "plt.xticks(rotation=90)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "We see in both cases that the outlier is \"Spider-Man: No Way Home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Domestic Box Office'] > (7*(10**8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Worldwide Box Office'] > (1*(10**9))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (17, 7)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "import seaborn as sns\n",
    "\n",
    "#improve resolution\n",
    "#comment this line if erroring on your machine/screen\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import natural language toolkit\n",
    "import nltk\n",
    "\n",
    "# download stopwords & punkt & VADER\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tweets_df['tweet_token'] = tweets_df['tweet_clean'].apply(word_tokenize)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweets_df['tweet_stop'] = tweets_df['tweet_token'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tweets_df['tweet_stem'] = tweets_df['tweet_stop'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distribution of words for F9 and Black Widow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words after stemming\n",
    "bw_tweets = tweets_df[tweets_df['movie'] == 'Black Widow']\n",
    "tweet_series = bw_tweets.squeeze()\n",
    "tweet_stem = tweet_series['tweet_stem'].apply(pd.Series).stack()\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "#calculate word frequency\n",
    "fdist_tweets = FreqDist(tweet_stem)\n",
    "#delete punctuation counts\n",
    "for punc in string.punctuation:\n",
    "    del fdist_tweets[punc]\n",
    "\n",
    "#get top 20 words\n",
    "fdist_tweets.plot(20, cumulative=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_tweets = tweets_df[tweets_df['movie'] == 'Black Widow']\n",
    "tweet_series = bw_tweets.squeeze()\n",
    "tweet_stem = tweet_series['tweet_stem'].apply(pd.Series).stack()\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "#calculate word frequency\n",
    "fdist_tweets = FreqDist(tweet_stem)\n",
    "#delete punctuation counts\n",
    "for punc in string.punctuation:\n",
    "    del fdist_tweets[punc]\n",
    "\n",
    "#get top 20 words\n",
    "fdist_tweets.plot(20, cumulative=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "test_tweet = tweets_df.iloc[0]['tweet_clean']\n",
    "print(test_tweet)\n",
    "print(analyser.polarity_scores(test_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame()\n",
    "sentiment_df['tweet_clean'] = tweets_df['tweet_clean']\n",
    "sentiment_df['sentiment'] = tweets_df['tweet_clean'].apply(analyser.polarity_scores)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_sentiment(sentiment_obj, category):\n",
    "    return sentiment_obj[category]\n",
    "sentiment_df['compound'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'compound'))\n",
    "sentiment_df['neg'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'neg'))\n",
    "sentiment_df['neu'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'neu'))\n",
    "sentiment_df['pos'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'pos'))\n",
    "sentiment_df.drop(columns=['sentiment'], inplace=True)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_to_label(compound_score):\n",
    "    if(compound_score >= 0.05): return 'pos'\n",
    "    if(compound_score <= -0.05): return 'neg'\n",
    "    return 'neu'\n",
    "\n",
    "sentiment_df['label'] = sentiment_df['compound'].apply(compound_to_label)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before', sentiment_df.shape)\n",
    "sentiment_df.drop(sentiment_df[sentiment_df.label == 'neu'].index, inplace=True)\n",
    "print('after', sentiment_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection: The actual act of scraping the data from twitter for our research project is in the clear regarding its eithcality as twitter is a public space. Because we only want the sentiment of the individuals in regards to the movies, their anonymity should be upheld. So, we are planning to only use their tweets and not them as an individual.\n",
    "\n",
    "Sentiment Analysis: Ideally we would like to not only see if any form of discussion on twitter about a movie increases its performance, we would also like to observe if whether the primary reasoning for performance is based on the the type of discussion being taken place. We would like to divide up the tweets into three; positive, negative or neutral sentiment. While there is a concern for ethics when using sentiment analysis, we believe that the context that we are using it in does not break any moral standards and we are transparent in our goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify who in your group worked on which parts of the project.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
