{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project : An Insight on the Correlation of Social Media Impressions and Box Office Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [  ] YES - make available\n",
    "* [ X ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we explore if several tweet factors indicate a likelihood of a higher box offices for the top 100 movies of 2021. We explore our data by graphing the box offices of our selection of movies, finding the frequency distribution of words in select movies and measuring sentiment for each tweet in our dataset. We move on to create linear regression models with scatterplots to measure correlations between tweet count and boxoffices as well as tweet sentiment and box offices. We find that our data supports our hypthothesis and that their is a corelation between the aforementioned variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "  - Fajar Dirham\n",
    "  - Robbie Kovar\n",
    "  - Erik Cisneros\n",
    "  - Julie Ngan\n",
    "  - Mohamed Abdilahi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the amount of positive and negative tweets affect how well American movies do in the box office?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "\n",
    "## Background & Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to quantify how social media affects the real world is not a new idea. The specific question we are trying to ask, relating social media impressions and box office success for movies, has been explored by other parties in the past. A thesis paper from the University of Miami school of communication found positive correlation coefficients between engagements in Instagram, Facebook, and Twitter and box office numbers[^dejesus]. In the paper, engagements were calculated by accounting for the followers of posts. The author took movies from Rotten Tomatoes, used Box Office Mojo for revenue data, and used Rival IQ (a social media platform analytics service). These positive correlation coefficients suggest that there \"exists a moderate or strong positive correlation between engagement rates and box office for limited release films\".\n",
    "\n",
    "Another similar study by Neuralink and Facebook hoping to uncover the impact social media has on a movie’s success, particularly box office sales, found that Facebook ads contributed a significant portion to a movie’s marketing (20%) despite only accounting for a small percentage of its expenditure (4%).[^meta] In other words, the budget spent on Facebook ads ended up having a larger impact than its cost would entail. In the study they acknowledge how social media has become a competitive platform for media consumption, likening it to how television was revolutionary in marketing back in its heyday. Similarly, our group acknowledges how social media has become an influential and impactful communication platform, replacing traditional methods of self-expression such as word of mouth with the publishing of public posts. As such we hope to uncover if the brief mention of movie titles in people’s posts, has the potential to drive up sales for movies.\n",
    "\n",
    "References (include links):\n",
    "- 1) De Jesus, Kimberly. “Social Media Engagement and Film Box Office.” University of Miami School of Communication, 2020. [^meta]: “New: Study Unveils Secrets to Box Office Marketing.” Meta for Business, https://www.facebook.com/business/m/verticals/entertainment-media/social-media-impact-on-movie-attendance.\n",
    "- 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that the more social media impressions a movie has before coming out results in it doing better in the box office in its opening weekend, regardless of if the impressions are positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1\n",
    "\n",
    "    Dataset Name: Movie Report\n",
    "    Link to the dataset: https://www.the-numbers.com/movies/report/All/All/All/All/All/All/United-States/All/All/None/None/2021/2021/None/None/None/None/None/None?show-release-date=On&show-domestic-box-office=On&show-international-box-office=On&show-worldwide-box-office=On&view-order-by=domestic-box-office&view-order-direction=desc\n",
    "    Number of observations: 100\n",
    "\n",
    "This dataset is the list of the top 100 American movies domestically, internationally, and worldwide. We will use this dataset to help us answer our research question on whether the amount of tweets is correlated to how well it does commercially.\n",
    "DataSet 2\n",
    "\n",
    "    Dataset Name: Tweets\n",
    "    Link to the dataset: N/A, webscraped\n",
    "    Number of observations: 801929\n",
    "\n",
    "This dataset is scraped from Twitter, using a 3rd party scraping tool, snscrape. Using the titles found in the Movie Report dataset, we will fetch the number of tweets that reference these titles, and list them with a tweet for each row. This dataset has a column marked 'movie_id' which corresponds to which movie the tweet is from and its index in the Movie Report datset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read MovieReport.csv into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Released</th>\n",
       "      <th>Title</th>\n",
       "      <th>Domestic\\r\\nBox Office</th>\n",
       "      <th>International\\r\\nBox Office</th>\n",
       "      <th>Worldwide\\r\\nBox Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 17, 2021</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>$804,617,772</td>\n",
       "      <td>$1,083,808,579</td>\n",
       "      <td>$1,888,426,351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sep 3, 2021</td>\n",
       "      <td>Shang-Chi and the Legend of the Ten R…</td>\n",
       "      <td>$224,543,292</td>\n",
       "      <td>$207,700,000</td>\n",
       "      <td>$432,243,292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oct 1, 2021</td>\n",
       "      <td>Venom: Let There be Carnage</td>\n",
       "      <td>$213,550,366</td>\n",
       "      <td>$288,050,013</td>\n",
       "      <td>$501,600,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jul 9, 2021</td>\n",
       "      <td>Black Widow</td>\n",
       "      <td>$183,651,655</td>\n",
       "      <td>$196,100,000</td>\n",
       "      <td>$379,751,655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun 25, 2021</td>\n",
       "      <td>F9: The Fast Saga</td>\n",
       "      <td>$173,005,945</td>\n",
       "      <td>$548,072,000</td>\n",
       "      <td>$721,077,945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Released                                   Title  \\\n",
       "1  Dec 17, 2021                 Spider-Man: No Way Home   \n",
       "2   Sep 3, 2021  Shang-Chi and the Legend of the Ten R…   \n",
       "3   Oct 1, 2021             Venom: Let There be Carnage   \n",
       "4   Jul 9, 2021                             Black Widow   \n",
       "5  Jun 25, 2021                       F9: The Fast Saga   \n",
       "\n",
       "  Domestic\\r\\nBox Office International\\r\\nBox Office Worldwide\\r\\nBox Office  \n",
       "1           $804,617,772              $1,083,808,579          $1,888,426,351  \n",
       "2           $224,543,292                $207,700,000            $432,243,292  \n",
       "3           $213,550,366                $288,050,013            $501,600,379  \n",
       "4           $183,651,655                $196,100,000            $379,751,655  \n",
       "5           $173,005,945                $548,072,000            $721,077,945  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('MovieReport.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 webscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation of webscraper\n",
    "#!pip install -q snscrape==0.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below takes in a movie title and returns movie titles for snscrape to query twitter with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_title(title):\n",
    "  title = title.lower()\n",
    "\n",
    "  #handle special cases\n",
    "  if(\"f9\" in title):\n",
    "    return [\"F9\", \"fast 9\", \"fast and furious 9\", \"f9 the fast saga\"]\n",
    "  if(\"shang-chi\" in title):\n",
    "    return [\"shang chi\", \"shang chi and the legend of the ten rings\"]\n",
    "  if(\"summer of soul\" in title):\n",
    "    return [\"summer of soul\", \"summer of soul or when the revolution cannot be televised\"]\n",
    "  if(\"roadrunner\" in title):\n",
    "    return ['Roadrunner', 'roadrunner anthony bourdain', 'road runner a film about anthony bourdain']\n",
    "  if(\"christmas with the chosen\" in title):\n",
    "    return [\"Christmas with the chosen\", 'christmas with the chosen the messengers']\n",
    "  if(\"quiet place\" in title):\n",
    "    return [\"a quiet place\", \"a quiet place part 2\", \"a quiet place part II\"]\n",
    "\n",
    "  to_return = []\n",
    "  \n",
    "  #handle dashes\n",
    "  title = title.replace(\"-\", \" \")\n",
    "\n",
    "  # handle colons\n",
    "  colon_split = title.split(':')\n",
    "  if(len(colon_split) > 1):\n",
    "    to_return.append(colon_split[0])\n",
    "    to_return.append(\" \".join(colon_split).replace(\"  \", \" \"))\n",
    "  else:\n",
    "    to_return.append(title)\n",
    "  \n",
    "\n",
    "  return to_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we iterate through list of movies to run the appropriate queries. A typical query is ran by snscrape with the words: \"{movie title} movie\". We are looking for tweets made in the first two months of a movie's release.\n",
    "\n",
    "READ BELOW BEFORE RUNNING:\n",
    "1. Results will be outputted to a folder that has to exist and is titles \"raw_tweets\"\n",
    "2. It takes hours for the queries to finish\n",
    "3. The code below only works if the \"data\" dataframe, which currently only has the contents of MovieReports.csv, has been cleaned. See the next section for how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def scrape_tweets():\n",
    "    for index,row in data.iterrows():\n",
    "        title = row['Title']\n",
    "        words = title.split()\n",
    "        \n",
    "        # Skip over movie titles with only 1 word since that will return too many tweets\n",
    "        if(len(words) == 1):\n",
    "            continue\n",
    "\n",
    "        since = row['Released'].strftime('%Y-%m-%d')\n",
    "        until = (row['Released'] + datetime.timedelta(days=61)).strftime('%Y-%m-%d')\n",
    "        filename = str(index) + '-' + title.lower().replace(' ', '')\n",
    "        filename = filename.replace(\"(\",\"\")\n",
    "        filename += '.txt'\n",
    "\n",
    "\n",
    "        titles = format_title(title)\n",
    "        for formatted_title in titles:\n",
    "            command = 'snscrape --jsonl --since ' + since + ' twitter-search \"' + formatted_title + ' movie until:' + until + '\" >> raw_tweets/' + filename\n",
    "            os.system('echo ' + filename)\n",
    "            os.system(command)\n",
    "\n",
    "#scrape_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Report Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Function for getting the total number of tweets for a movie title\n",
    "# from_date - datetime object to start search\n",
    "# to_date - datetime object to stop search\n",
    "# title - string title of movie\n",
    "# returns int number of tweets for the movie \n",
    "def num_tweets(from_date, to_date, title):\n",
    "    start = str(from_date).replace(' 00:00:00', '')\n",
    "    end = str(to_date).replace(' 00:00:00', '')\n",
    "\n",
    "    os.system(f\"snscrape --since {start} twitter-search '{title} until:{end}' > result-tweets.txt\")\n",
    "    if os.stat(\"result-tweets.txt\").st_size == 0:\n",
    "       counter = 0\n",
    "    else:\n",
    "       df = pd.read_csv('result-tweets.txt', names=['link'])\n",
    "       counter = df.size\n",
    "    os.remove('result-tweets.txt')\n",
    "    print('Number Of Tweets : '+ str(counter))\n",
    "    return counter\n",
    "\n",
    "# Function for getting the total number of tweets for a movie title\n",
    "# from_date - datetime object to start search\n",
    "# to_date - datetime object to stop search\n",
    "# title - string title of movie\n",
    "# N - int number of posts to fetch\n",
    "# returns list of first N tweets about the movie title \n",
    "def get_N_posts(from_date, to_date, title, N):\n",
    "  posts_list = []\n",
    "  start = str(from_date).replace(' 00:00:00', '')\n",
    "  end = str(to_date).replace(' 00:00:00', '')\n",
    "  os.system(\"snscrape --format '{content!r}'\"+ f\" --max-results {N} --since {start} twitter-search '{title} until:{end}' > tweets.txt\")\n",
    "  if os.stat(\"tweets.txt\").st_size == 0:\n",
    "    os.remove('tweets.txt')\n",
    "    return posts_list\n",
    "  else:\n",
    "    df = pd.read_csv('tweets.txt', names=['content'])\n",
    "    for row in df['content'].iteritems():\n",
    "      posts_list.append(row)\n",
    "    os.remove('tweets.txt')\n",
    "    return posts_list\n",
    "\n",
    "# Function for converting date strings into pandas datatime objects\n",
    "# start - string datetime to start search\n",
    "# end - string datetime to stop search\n",
    "# title - string title of movie\n",
    "# returns int number of tweets for the movie\n",
    "def standardize_date(str): \n",
    "  try:\n",
    "    str = str.strip()\n",
    "\n",
    "    str = str.replace('Jan ', \"01/\")\n",
    "    str = str.replace('Feb ', \"02/\")\n",
    "    str = str.replace('Mar ', \"03/\")\n",
    "    str = str.replace('Apr ', \"04/\")\n",
    "    str = str.replace('May ', \"05/\")\n",
    "    str = str.replace('Jun ', \"06/\")\n",
    "    str = str.replace('Jul ', \"07/\")\n",
    "    str = str.replace('Aug ', \"08/\")\n",
    "    str = str.replace('Sep ', \"09/\")\n",
    "    str = str.replace('Oct ', \"10/\")\n",
    "    str = str.replace('Nov ', \"11/\")\n",
    "    str = str.replace('Dec ', \"12/\")\n",
    "\n",
    "    str = str.replace(', ', \"/\")\n",
    "\n",
    "    str = str.replace('/1/', \"/01/\")\n",
    "    str = str.replace('/2/', \"/02/\")\n",
    "    str = str.replace('/3/', \"/03/\")\n",
    "    str = str.replace('/4/', \"/04/\")\n",
    "    str = str.replace('/5/', \"/05/\")\n",
    "    str = str.replace('/6/', \"/06/\")\n",
    "    str = str.replace('/7/', \"/07/\")\n",
    "    str = str.replace('/8/', \"/08/\")\n",
    "    str = str.replace('/9/', \"/09/\")\n",
    "\n",
    "    out = str\n",
    "  except:\n",
    "    out = \"n/a\" \n",
    "\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Released</th>\n",
       "      <th>Title</th>\n",
       "      <th>Domestic Box Office</th>\n",
       "      <th>International Box Office</th>\n",
       "      <th>Worldwide Box Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>The Marksman</td>\n",
       "      <td>15566093.0</td>\n",
       "      <td>5631181.0</td>\n",
       "      <td>21197274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>Wrong Turn</td>\n",
       "      <td>1251184.0</td>\n",
       "      <td>2392576.0</td>\n",
       "      <td>3643760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>The Little Things</td>\n",
       "      <td>15342746.0</td>\n",
       "      <td>14392476.0</td>\n",
       "      <td>29735222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>Nomadland</td>\n",
       "      <td>2180000.0</td>\n",
       "      <td>36818715.0</td>\n",
       "      <td>38998715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>Judas and the Black Messiah</td>\n",
       "      <td>5478009.0</td>\n",
       "      <td>1580271.0</td>\n",
       "      <td>7058280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Released                        Title  Domestic Box Office  \\\n",
       "0 2021-01-15                 The Marksman           15566093.0   \n",
       "1 2021-01-26                   Wrong Turn            1251184.0   \n",
       "2 2021-01-29            The Little Things           15342746.0   \n",
       "3 2021-01-29                    Nomadland            2180000.0   \n",
       "4 2021-02-12  Judas and the Black Messiah            5478009.0   \n",
       "\n",
       "   International Box Office  Worldwide Box Office  \n",
       "0                 5631181.0            21197274.0  \n",
       "1                 2392576.0             3643760.0  \n",
       "2                14392476.0            29735222.0  \n",
       "3                36818715.0            38998715.0  \n",
       "4                 1580271.0             7058280.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #simple renaming of columns so it can be easier to read\n",
    "data = data.rename(columns={\"Domestic\\r\\nBox Office\":\"Domestic Box Office\", \"International\\r\\nBox Office\":\"International Box Office\", \n",
    "            \"Worldwide\\r\\nBox Office\":\"Worldwide Box Office\"})\n",
    "#data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Transformation of release date string to 'datetime' objects\n",
    "data['Released'] = data['Released'].apply(standardize_date)\n",
    "data['Released'] = data['Released'].apply(pd.to_datetime)\n",
    "\n",
    "# Sort Movies by release date\n",
    "data = data.sort_values(by='Released')\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "# Remove dollar signs and commas from the box office numbers and convert them to floats\n",
    "data['Domestic Box Office'] = data['Domestic Box Office'].str.replace('$','')\n",
    "data['Domestic Box Office'] = data['Domestic Box Office'].str.replace(',','').astype(float)\n",
    "data['International Box Office'] = data['International Box Office'].str.replace('$','')\n",
    "data['International Box Office'] = data['International Box Office'].str.replace(',','').astype(float)\n",
    "data['Worldwide Box Office'] = data['Worldwide Box Office'].str.replace('$','')\n",
    "data['Worldwide Box Office'] = data['Worldwide Box Office'].str.replace(',','').astype(float)\n",
    "\n",
    "# Remove null\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and clean Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we iterate through all the raw tweet data and pull out the content, placing them in a folder that has to exist and is titled \"processed_tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_file(filename):\n",
    "    # Using readlines()\n",
    "    file1 = open('raw_tweets/' + filename, 'r')\n",
    "    file2 = open('processed_tweets/' + filename, 'a')\n",
    "    Lines = file1.readlines()\n",
    "    \n",
    "    count = 0\n",
    "    # Strips the newline character\n",
    "    file2.write(\"tweet\\n\")\n",
    "    for line in Lines:\n",
    "        count += 1\n",
    "        obj = json.loads(line.strip())\n",
    "        content = obj['content']\n",
    "        content = content.replace(\",\", \"\")\n",
    "        content = content.replace(\"\\n\", \"\")\n",
    "        content = content.replace(\"\\r\", \"\")\n",
    "        file2.write(content + '\\n')\n",
    "    \n",
    "    file1.close()\n",
    "    file2.close()\n",
    "\n",
    "def process_tweets():\n",
    "    yourpath = './raw_tweets/'\n",
    "    for root, dirs, files in os.walk(yourpath, topdown=True):\n",
    "        for name in files:\n",
    "            process_file(name)\n",
    "\n",
    "#process_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take all those processed tweets and put them all into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801929, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>movie</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SpiderManMovie @HarryHolland99 @IMAX @DolbyCi...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@A_C_Mitchell @molly_kraus @MarvelStudios @Spi...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Spider Man trailer and stock prices”… Story |...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Gamer21690 @SpiderManMovie too obsessed</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking forward to Spider-Man tonight. If anyo...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet                    movie  \\\n",
       "0  @SpiderManMovie @HarryHolland99 @IMAX @DolbyCi...  Spider-Man: No Way Home   \n",
       "1  @A_C_Mitchell @molly_kraus @MarvelStudios @Spi...  Spider-Man: No Way Home   \n",
       "2  “Spider Man trailer and stock prices”… Story |...  Spider-Man: No Way Home   \n",
       "3           @Gamer21690 @SpiderManMovie too obsessed  Spider-Man: No Way Home   \n",
       "4  Looking forward to Spider-Man tonight. If anyo...  Spider-Man: No Way Home   \n",
       "\n",
       "   movie_id  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_csv():\n",
    "  tweet_dfs = []\n",
    "\n",
    "  def create_dfs(filename):\n",
    "    temp_df = pd.read_csv('processed_tweets/' + filename)\n",
    "    id = int(filename[:filename.index('-')])\n",
    "    temp_df['movie'] = data.iloc[id - 1]['Title']\n",
    "    temp_df['movie_id'] = id\n",
    "    tweet_dfs.append(temp_df)\n",
    "\n",
    "  yourpath = './processed_tweets/'\n",
    "  for root, dirs, files in os.walk(yourpath, topdown=False):\n",
    "    for name in files:\n",
    "          create_dfs(name)\n",
    "\n",
    "  tweets_df = pd.concat(tweet_dfs)\n",
    "  tweets_df.sort_values(by='movie_id', inplace=True)\n",
    "  tweets_df.reset_index(inplace=True, drop=True)\n",
    "  tweets_df.drop_duplicates(subset=[\"tweet\"], inplace=True)\n",
    "  tweets_df.to_csv('tweets.csv.zip', index=False)\n",
    "\n",
    "# This is how we used the data frame going forward after running\n",
    "# generate_csv()\n",
    "tweets_df = pd.read_csv(\"tweets.csv\")\n",
    "print(tweets_df.shape)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we clean the tweets, removing hashtags and mentions but keeping punctuation as that may convey information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpiderMan has saved the movie going experience!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>movie</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SpiderManMovie @HarryHolland99 @IMAX @DolbyCi...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "      <td>SpiderMan has saved the movie going experience!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@A_C_Mitchell @molly_kraus @MarvelStudios @Spi...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes- so good! Grab extra napkins with your pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Spider Man trailer and stock prices”… Story |...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "      <td>“Spider Man trailer and stock prices”… Story |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Gamer21690 @SpiderManMovie too obsessed</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "      <td>too obsessed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking forward to Spider-Man tonight. If anyo...</td>\n",
       "      <td>Spider-Man: No Way Home</td>\n",
       "      <td>1</td>\n",
       "      <td>Looking forward to Spider-Man tonight. If anyo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet                    movie  \\\n",
       "0  @SpiderManMovie @HarryHolland99 @IMAX @DolbyCi...  Spider-Man: No Way Home   \n",
       "1  @A_C_Mitchell @molly_kraus @MarvelStudios @Spi...  Spider-Man: No Way Home   \n",
       "2  “Spider Man trailer and stock prices”… Story |...  Spider-Man: No Way Home   \n",
       "3           @Gamer21690 @SpiderManMovie too obsessed  Spider-Man: No Way Home   \n",
       "4  Looking forward to Spider-Man tonight. If anyo...  Spider-Man: No Way Home   \n",
       "\n",
       "   movie_id                                        tweet_clean  \n",
       "0         1  SpiderMan has saved the movie going experience!!!  \n",
       "1         1  Yes- so good! Grab extra napkins with your pop...  \n",
       "2         1  “Spider Man trailer and stock prices”… Story |...  \n",
       "3         1                                       too obsessed  \n",
       "4         1  Looking forward to Spider-Man tonight. If anyo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process the tweets first\n",
    "\n",
    "def clean_text(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    to_return = ''\n",
    "    for word in text.split():\n",
    "        if not '@' in word and not 'https:' in word:\n",
    "            to_return += word + \" \"\n",
    "\n",
    "    to_return = to_return.replace(\"#\",\"\")\n",
    "    return to_return[0:len(to_return)-1]\n",
    "\n",
    "test_clean = clean_text(tweets_df.iloc[0]['tweet'])\n",
    "print(test_clean)\n",
    "tweets_df[\"tweet_clean\"] = tweets_df['tweet'].apply(clean_text)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Released</th>\n",
       "      <th>Title</th>\n",
       "      <th>Domestic Box Office</th>\n",
       "      <th>International Box Office</th>\n",
       "      <th>Worldwide Box Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>The Marksman</td>\n",
       "      <td>15566093.0</td>\n",
       "      <td>5631181.0</td>\n",
       "      <td>21197274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>Wrong Turn</td>\n",
       "      <td>1251184.0</td>\n",
       "      <td>2392576.0</td>\n",
       "      <td>3643760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>The Little Things</td>\n",
       "      <td>15342746.0</td>\n",
       "      <td>14392476.0</td>\n",
       "      <td>29735222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>Nomadland</td>\n",
       "      <td>2180000.0</td>\n",
       "      <td>36818715.0</td>\n",
       "      <td>38998715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>Judas and the Black Messiah</td>\n",
       "      <td>5478009.0</td>\n",
       "      <td>1580271.0</td>\n",
       "      <td>7058280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>The King’s Man</td>\n",
       "      <td>37176373.0</td>\n",
       "      <td>83948927.0</td>\n",
       "      <td>121125300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>The Matrix Resurrections</td>\n",
       "      <td>37686805.0</td>\n",
       "      <td>118781012.0</td>\n",
       "      <td>156467817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>Sing 2</td>\n",
       "      <td>162790990.0</td>\n",
       "      <td>234806442.0</td>\n",
       "      <td>397597432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2021-12-25</td>\n",
       "      <td>American Underdog: The Kurt Warner Story</td>\n",
       "      <td>26514814.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26514814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021-12-25</td>\n",
       "      <td>A Journal for Jordan</td>\n",
       "      <td>6400032.0</td>\n",
       "      <td>68499.0</td>\n",
       "      <td>6468531.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Released                                     Title  Domestic Box Office  \\\n",
       "0  2021-01-15                              The Marksman           15566093.0   \n",
       "1  2021-01-26                                Wrong Turn            1251184.0   \n",
       "2  2021-01-29                         The Little Things           15342746.0   \n",
       "3  2021-01-29                                 Nomadland            2180000.0   \n",
       "4  2021-02-12               Judas and the Black Messiah            5478009.0   \n",
       "..        ...                                       ...                  ...   \n",
       "95 2021-12-22                            The King’s Man           37176373.0   \n",
       "96 2021-12-22                  The Matrix Resurrections           37686805.0   \n",
       "97 2021-12-22                                    Sing 2          162790990.0   \n",
       "98 2021-12-25  American Underdog: The Kurt Warner Story           26514814.0   \n",
       "99 2021-12-25                      A Journal for Jordan            6400032.0   \n",
       "\n",
       "    International Box Office  Worldwide Box Office  \n",
       "0                  5631181.0            21197274.0  \n",
       "1                  2392576.0             3643760.0  \n",
       "2                 14392476.0            29735222.0  \n",
       "3                 36818715.0            38998715.0  \n",
       "4                  1580271.0             7058280.0  \n",
       "..                       ...                   ...  \n",
       "95                83948927.0           121125300.0  \n",
       "96               118781012.0           156467817.0  \n",
       "97               234806442.0           397597432.0  \n",
       "98                       0.0            26514814.0  \n",
       "99                   68499.0             6468531.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size\n",
    "For this dataset we have 100 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness\n",
    "Searching for any anomalous entries we found that 6 movies had an International Box Office of 0. We believe these movies didn't have an international box office because they only released domestically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic_only =  data[data['International Box Office'] == 0]\n",
    "domestic_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using box office as a measure of success for a movie, we will remove the aforementioned entries. Their lack of an international box office, makes it difficult to compare them with other movies at an international scope. Additionally it hinders their worldwide box office making them appear less successful than other movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['International Box Office'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a histogram for the release date of movies, we see that it is fairly uniformly distributed. There is a slight lack of movies during the first quarter the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='Released', bins=24)\n",
    "plt.title('Distribution of Movie Release Date Across 2021')\n",
    "plt.xticks(rotation=45)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting for Box Office success, we see all three distributions are highly skewed right. We also spot a few outliers who earned huge box offices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='Domestic Box Office', bins=24)\n",
    "plt.title('Distribution of Domestic Box Office')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='International Box Office', bins=24)\n",
    "plt.title('Distribution of International Box Office')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x='Worldwide Box Office', bins=24)\n",
    "plt.title('Distribution of Worldwide Box Office')\n",
    "plt.xticks(rotation=90)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "We see in both cases that the outlier is \"Spider-Man: No Way Home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Domestic Box Office'] > (7*(10**8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Worldwide Box Office'] > (1*(10**9))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fajardirham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/fajardirham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/fajardirham/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (17, 7)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "import seaborn as sns\n",
    "\n",
    "#improve resolution\n",
    "#comment this line if erroring on your machine/screen\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import natural language toolkit\n",
    "import nltk\n",
    "\n",
    "# download stopwords & punkt & VADER\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tweets_df['tweet_token'] = tweets_df['tweet_clean'].apply(word_tokenize)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweets_df['tweet_stop'] = tweets_df['tweet_token'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tweets_df['tweet_stem'] = tweets_df['tweet_stop'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distribution of words for F9 and Black Widow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words after stemming\n",
    "bw_tweets = tweets_df[tweets_df['movie'] == 'Black Widow']\n",
    "tweet_series = bw_tweets.squeeze()\n",
    "tweet_stem = tweet_series['tweet_stem'].apply(pd.Series).stack()\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "#calculate word frequency\n",
    "fdist_tweets = FreqDist(tweet_stem)\n",
    "#delete punctuation counts\n",
    "for punc in string.punctuation:\n",
    "    del fdist_tweets[punc]\n",
    "\n",
    "#get top 20 words\n",
    "fdist_tweets.plot(20, cumulative=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_tweets = tweets_df[tweets_df['movie'] == 'Black Widow']\n",
    "tweet_series = bw_tweets.squeeze()\n",
    "tweet_stem = tweet_series['tweet_stem'].apply(pd.Series).stack()\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "#calculate word frequency\n",
    "fdist_tweets = FreqDist(tweet_stem)\n",
    "#delete punctuation counts\n",
    "for punc in string.punctuation:\n",
    "    del fdist_tweets[punc]\n",
    "\n",
    "#get top 20 words\n",
    "fdist_tweets.plot(20, cumulative=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "test_tweet = tweets_df.iloc[0]['tweet_clean']\n",
    "print(test_tweet)\n",
    "print(analyser.polarity_scores(test_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame()\n",
    "sentiment_df['tweet_clean'] = tweets_df['tweet_clean']\n",
    "sentiment_df['sentiment'] = tweets_df['tweet_clean'].apply(analyser.polarity_scores)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_sentiment(sentiment_obj, category):\n",
    "    return sentiment_obj[category]\n",
    "sentiment_df['compound'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'compound'))\n",
    "sentiment_df['neg'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'neg'))\n",
    "sentiment_df['neu'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'neu'))\n",
    "sentiment_df['pos'] = sentiment_df['sentiment'].apply(lambda x: spread_sentiment(x, 'pos'))\n",
    "sentiment_df.drop(columns=['sentiment'], inplace=True)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by and mean compound scores\n",
    "grouped = sentiment_df.groupby(by=['movie_id'])\n",
    "mean_sentiment_df = grouped.mean()\n",
    "mean_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of tweets per movie\n",
    "count_sentiment_df = grouped.count()\n",
    "movie_aggregate_df = mean_sentiment_df.merge(count_sentiment_df['tweet_clean'], left_index=True, right_on='movie_id')\n",
    "movie_aggregate_df.columns = ['compound_mean', 'neg_mean', 'neu_mean', 'pos_mean', 'num_tweets']\n",
    "movie_aggregate_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_aggregate_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fajardirham/Desktop/ucsd/cogs108/Group012Sp22/FinalProjectGroup012Sp22.ipynb Cell 70'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fajardirham/Desktop/ucsd/cogs108/Group012Sp22/FinalProjectGroup012Sp22.ipynb#ch0000061?line=0'>1</a>\u001b[0m \u001b[39m# Join with box office\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fajardirham/Desktop/ucsd/cogs108/Group012Sp22/FinalProjectGroup012Sp22.ipynb#ch0000061?line=1'>2</a>\u001b[0m movies_df \u001b[39m=\u001b[39m data\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fajardirham/Desktop/ucsd/cogs108/Group012Sp22/FinalProjectGroup012Sp22.ipynb#ch0000061?line=2'>3</a>\u001b[0m joined_df \u001b[39m=\u001b[39m movie_aggregate_df\u001b[39m.\u001b[39mmerge(movies_df, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmovie_id\u001b[39m\u001b[39m'\u001b[39m, right_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fajardirham/Desktop/ucsd/cogs108/Group012Sp22/FinalProjectGroup012Sp22.ipynb#ch0000061?line=3'>4</a>\u001b[0m joined_df\u001b[39m.\u001b[39mhead(\u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movie_aggregate_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Join with box office\n",
    "movies_df = data\n",
    "joined_df = movie_aggregate_df.merge(movies_df, left_on='movie_id', right_index=True)\n",
    "joined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tweet counts\n",
    "sorted_count_df = joined_df.sort_values(by='num_tweets', ascending=True)\n",
    "sorted_count_plot = sns.barplot(data=sorted_count_df, y='num_tweets', x='movie')\n",
    "for item in sorted_count_plot.get_xticklabels():\n",
    "    item.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe num tweets\n",
    "joined_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get rid of some outliers and low tweet counts to make our predictions more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove low count tweets for correlation, we will use movies with 1000 tweets or above\n",
    "full_joined_df = joined_df\n",
    "joined_df = joined_df[joined_df['num_tweets'] > 1000]\n",
    "\n",
    "# Remove spider man\n",
    "joined_df = joined_df[joined_df['num_tweets'] < 100000]\n",
    "\n",
    "print(joined_df.shape)\n",
    "print(joined_df.head())\n",
    "\n",
    "sorted_count_df = joined_df.sort_values(by='num_tweets', ascending=True)\n",
    "sorted_count_plot = sns.barplot(data=sorted_count_df, y='num_tweets', x='movie')\n",
    "for item in sorted_count_plot.get_xticklabels():\n",
    "    item.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connections between Average Compound Scores and Domestic Box Office\n",
    "\n",
    "Let's see if there is a direct connection between average compound scores and domestic box office numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_cash(string):\n",
    "    string = string.replace('$','').replace(',','')\n",
    "    return float(string)\n",
    "\n",
    "correlation_df = pd.DataFrame()\n",
    "correlation_df['compound'] = joined_df['compound_mean']\n",
    "correlation_df['domestic'] = joined_df['domestic'].apply(std_cash)\n",
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='compound', y='domestic', data=correlation_df, ci=None, aspect=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('domestic ~ compound', correlation_df)\n",
    "model = sm.OLS(outcome, predictors)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "There does not seem to be a direct correlation between average compound scores of tweets 2 months after release and domestic box office numbers. This is evident from the relatively high p value for our predictor number and low R squared, indicated that the pearson correlation number is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Between Movie Tweet Count & Domestic Box Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df['num_tweets'] = joined_df['num_tweets']\n",
    "correlation_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='num_tweets', y='domestic', data=correlation_df,\n",
    "          ci=None, aspect=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('domestic ~ num_tweets', correlation_df)\n",
    "model = sm.OLS(outcome, predictors)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "There does seem to be a linear relationship between the number of tweets and domestic box office numbers. The p value for the predictor is low and the pearson coefficient squared seems to be high enough to suggest a positive correlation (R^2 = 0.25 -> R = 0.5). The OLS model suggests that for every tweet, box office numbers would increase by $1847.\n",
    "\n",
    "Realistically, this makes some sense. Assuming it costs $10 for each movie ticket, $1847 would equal to about 184 people buying tickets for a movie. It is within the realm of possibility that only one out of 184 people would tweet about a movie they have seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Between Tweet Count of Differing Sentiments & Domestic Box Office \n",
    "\n",
    "First we will add labels to our tweets (pos, neg, and neu). Then we will add up the number of labels per movie. Then we will see if there is a correlation between the number of labeled tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_to_label(compound_score):\n",
    "    if(compound_score >= 0.05): return 'pos'\n",
    "    if(compound_score <= -0.05): return 'neg'\n",
    "    return 'neu'\n",
    "\n",
    "sentiment_df['label'] = sentiment_df['compound'].apply(compound_to_label)\n",
    "sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sentiment_df[sentiment_df['label'] == 'pos']\n",
    "neu_df = sentiment_df[sentiment_df['label'] == 'neu']\n",
    "neg_df = sentiment_df[sentiment_df['label'] == 'neg']\n",
    "\n",
    "\n",
    "pos_grouped = pos_df.groupby(by=['movie_id'])\n",
    "pos_count = pos_grouped.count()['tweet_clean']\n",
    "neu_grouped = neu_df.groupby(by=['movie_id'])\n",
    "neu_count = neu_grouped.count()['tweet_clean']\n",
    "neg_grouped = neg_df.groupby(by=['movie_id'])\n",
    "neg_count = neg_grouped.count()['tweet_clean']\n",
    "labeled_count_df = pd.DataFrame()\n",
    "labeled_count_df['pos_count'] = pos_count\n",
    "labeled_count_df['neu_count'] = neu_count\n",
    "labeled_count_df['neg_count'] = neg_count\n",
    "labeled_count_df['num_tweets'] = labeled_count_df['pos_count'] + labeled_count_df['neu_count'] + labeled_count_df['neg_count']\n",
    "\n",
    "# Remove outliers and low tweet counts\n",
    "labeled_count_df = labeled_count_df[labeled_count_df['num_tweets'] > 1000]\n",
    "labeled_count_df = labeled_count_df[labeled_count_df['num_tweets'] < 100000]\n",
    "\n",
    "# Add domestic\n",
    "labeled_count_df['domestic'] = correlation_df['domestic']\n",
    "\n",
    "labeled_count_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pos\n",
    "outcome, predictors = patsy.dmatrices('domestic ~ pos_count', labeled_count_df)\n",
    "model = sm.OLS(outcome, predictors)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "sns.lmplot(x='pos_count', y='domestic', \n",
    "           data=labeled_count_df, ci=None, aspect=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot neu\n",
    "outcome, predictors = patsy.dmatrices('domestic ~ neu_count', labeled_count_df)\n",
    "model = sm.OLS(outcome, predictors)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "sns.lmplot(x='neu_count', y='domestic', \n",
    "           data=labeled_count_df, ci=None, aspect=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot neg\n",
    "outcome, predictors = patsy.dmatrices('domestic ~ neg_count', labeled_count_df)\n",
    "model = sm.OLS(outcome, predictors)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "sns.lmplot(x='neg_count', y='domestic', \n",
    "           data=labeled_count_df, ci=None, aspect=1.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Just by looking at the graphs, the sentiments of the tweets do not matter as much as the more tweets generally equate to higher domestic box office numbers. We'll now use OLS to see how each of the labels correlate to the domestic numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('domestic ~ pos_count + neu_count + neg_count', labeled_count_df)\n",
    "model = sm.OLS(outcome, predictors)\n",
    "pos_results = model.fit()\n",
    "\n",
    "print(pos_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "According to this OLS predictor, the amount of neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('domestic ~ compound + num_tweets + compound*num_tweets', correlation_df)\n",
    "model = sm.OLS(outcome, predictors)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection: The actual act of scraping the data from twitter for our research project is in the clear regarding its eithcality as twitter is a public space. Because we only want the sentiment of the individuals in regards to the movies, their anonymity should be upheld. So, we are planning to only use their tweets and not them as an individual.\n",
    "\n",
    "Sentiment Analysis: Ideally we would like to not only see if any form of discussion on twitter about a movie increases its performance, we would also like to observe if whether the primary reasoning for performance is based on the the type of discussion being taken place. We would like to divide up the tweets into three; positive, negative or neutral sentiment. While there is a concern for ethics when using sentiment analysis, we believe that the context that we are using it in does not break any moral standards and we are transparent in our goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify who in your group worked on which parts of the project.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
